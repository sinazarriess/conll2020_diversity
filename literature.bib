
@InBook{Grice1975,
  pages     = {41 - 58},
  title     = {Logic and Conversation},
  publisher = {Brill},
  year      = {1975},
  author    = {H. P. Grice},
  address   = {Leiden, Niederlande},
  isbn      = {9789004368576},
  doi       = {https://doi.org/10.1163/9789004368811_003},
  url       = {https://brill.com/view/book/edcoll/9789004368811/BP000003.xml},
}

@Article{Cruse1977,
  author    = {D. A. Cruse},
  title     = {The Pragmatics of Lexical Specificity},
  journal   = {Journal of Linguistics},
  year      = {1977},
  volume    = {13},
  number    = {2},
  pages     = {153--164},
  issn      = {00222267, 14697742},
  note      = {- Einfluss des situativen Kontext auf Spezifizität von Referenz},
  file      = {Cruse1977.odt:Cruse1977.odt:OpenDocument text},
  groups    = {Specificity, Pragmatics, General and Cognitive Lingustics},
  publisher = {Cambridge University Press},
  url       = {http://www.jstor.org/stable/4175393},
}

@Article{Hovy1987,
  author   = {Eduard Hovy},
  title    = {Generating natural language under pragmatic constraints},
  journal  = {Journal of Pragmatics},
  year     = {1987},
  volume   = {11},
  number   = {6},
  pages    = {689 - 719},
  issn     = {0378-2166},
  abstract = {Though much work in natural language generation remains to be done with regard to syntax, the main stumbling block that prevents existing generators from easily producing coherent paragraphs is our lack of understanding of text planning. To remedy this, we should view generations preeminently as a planning task; that is, we should study the goals that underlie text production, the plans that help achieve these goals, and the ways the plans can interact with grammar. A clue to the nature of these goals is the fact that people say the same thing in various ways. They can vary the content and form of their text when they want to convey more information than is contained in the literal meanings of their words. This information expresses the speaker's interpersonal goals toward the hearer and, in general, his perception of the pragmatic aspects of the conversation. This paper identifies goals that arise from pragmatic aspects of the conversation, plans and strategies to achieve them, and how they constrain the decisions a generator has to make during the realization process. To illustrate some of these ideas, a computer program is described which produces stylistically appropriate texts from a single representation under various settings that model pragmatic circumstances.},
  doi      = {https://doi.org/10.1016/0378-2166(87)90109-3},
  url      = {http://www.sciencedirect.com/science/article/pii/0378216687901093},
}

@Article{Reiter1991,
  author   = {Reiter, Ehud},
  title    = {A new model of lexical choice for nouns},
  journal  = {Computational Intelligence},
  year     = {1991},
  volume   = {7},
  number   = {4},
  pages    = {240-251},
  abstract = {Natural language generation systems should choose nouns by searching for lexical units that (i) are known to the user; (ii) truthfully describe the object being lexicalised; (iii) convey sufficient information to fulfill the system's underlying communicative goals; and (iv) are maximal under a lexical preference function. This model of lexical choice allows a clean separation to be made between what the system knows about the object being lexicalized and what it wishes to communicate about this object. The model also allows lexical choice to be biased towards basic-level and other preferred lexical units. Les systèmes de génération du langage naturel devraient choisir des noms en recherchant des unités lexicales (i) qui soient connues de ľutilisateur, (ii) qui décrivent fidèlement ľobjet soumis à un traitement lexical, (iii) qui transmettent suffisamment ?information pour répondre aux objectifs de communication du système, et (iv) qui soient maximales dans une fonction de préférence lexicale. Ce modéle de choix lexical permet une nette séparation entre ce que le système sait à propos de ľobjet soumis à un traitement lexical et ce qu'il souhaite communiquer à propos de cet objet. Le modèle permet également au choix lexical ?avoir un préjugé vis-à-vis les unités lexicales de niveau de base et autres unités lexicales préférées.},
  doi      = {10.1111/j.1467-8640.1991.tb00398.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8640.1991.tb00398.x},
  keywords = {natural language generation, lexical choice, content determination, conversational implicature., génération du langage naturel, choix lexical, détermination du contenu, implicatures conversationnelles., Traduit par la redaction},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.1991.tb00398.x},
}

@Article{Parikh1994,
  author    = {Rohit Parikh},
  title     = {Vagueness and Utility: The Semantics of Common Nouns},
  journal   = {Linguistics and Philosophy},
  year      = {1994},
  volume    = {17},
  number    = {6},
  pages     = {521--535},
  doi       = {10.1007/BF00985317},
  publisher = {Springer},
}

@Article{Brennan1996,
  author  = {Susan E. Brennan and Herbert H. Clark},
  title   = {Conceptual pacts and lexical choice in conversation.},
  journal = {Journal of experimental psychology. Learning, memory, and cognition},
  year    = {1996},
  volume  = {22 6},
  pages   = {1482-93},
}

@InProceedings{Papineni2002,
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  title     = {{B}leu: a Method for Automatic Evaluation of Machine Translation},
  booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
  year      = {2002},
  pages     = {311--318},
  address   = {Philadelphia, Pennsylvania, USA},
  month     = jul,
  publisher = {Association for Computational Linguistics},
  doi       = {10.3115/1073083.1073135},
  url       = {https://www.aclweb.org/anthology/P02-1040},
}

@Article{Reiter2002,
  author  = {Reiter, Ehud and Sripada, Somayajulu},
  title   = {Squibs and Discussions: Human Variation and Lexical Choice},
  journal = {Computational Linguistics},
  year    = {2002},
  volume  = {28},
  number  = {4},
  pages   = {545--553},
  doi     = {10.1162/089120102762671981},
  url     = {https://www.aclweb.org/anthology/J02-4007},
}

@Article{Graves2012,
  author      = {Alex Graves},
  title       = {Sequence Transduction with Recurrent Neural Networks},
  abstract    = {Many machine learning tasks can be expressed as the transformation---or \emph{transduction}---of input sequences into output sequences: speech recognition, machine translation, protein secondary structure prediction and text-to-speech to name but a few. One of the key challenges in sequence transduction is learning to represent both the input and output sequences in a way that is invariant to sequential distortions such as shrinking, stretching and translating. Recurrent neural networks (RNNs) are a powerful sequence learning architecture that has proven capable of learning such representations. However RNNs traditionally require a pre-defined alignment between the input and output sequences to perform transduction. This is a severe limitation since \emph{finding} the alignment is the most difficult aspect of many sequence transduction problems. Indeed, even determining the length of the output sequence is often challenging. This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence. Experimental results for phoneme recognition are provided on the TIMIT speech corpus.},
  date        = {2012-11-14},
  eprint      = {1211.3711v1},
  eprintclass = {cs.NE},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1211.3711v1:PDF},
  keywords    = {cs.NE, cs.LG, stat.ML},
}

@Article{Vedantam2014,
  author      = {Ramakrishna Vedantam and C. Lawrence Zitnick and Devi Parikh},
  title       = {CIDEr: Consensus-based Image Description Evaluation},
  abstract    = {Automatically describing an image with a sentence is a long-standing challenge in computer vision and natural language processing. Due to recent progress in object detection, attribute classification, action recognition, etc., there is renewed interest in this area. However, evaluating the quality of descriptions has proven to be challenging. We propose a novel paradigm for evaluating image descriptions that uses human consensus. This paradigm consists of three main parts: a new triplet-based method of collecting human annotations to measure consensus, a new automated metric (CIDEr) that captures consensus, and two new datasets: PASCAL-50S and ABSTRACT-50S that contain 50 sentences describing each image. Our simple metric captures human judgment of consensus better than existing metrics across sentences generated by various sources. We also evaluate five state-of-the-art image description approaches using this new protocol and provide a benchmark for future comparisons. A version of CIDEr named CIDEr-D is available as a part of MS COCO evaluation server to enable systematic evaluation and benchmarking.},
  date        = {2014-11-20},
  eprint      = {1411.5726v2},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1411.5726v2:PDF},
  keywords    = {cs.CV, cs.CL, cs.IR},
}

@Article{Lin2014,
  author      = {Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
  title       = {Microsoft COCO: Common Objects in Context},
  abstract    = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  date        = {2014-05-01},
  eprint      = {1405.0312v3},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1405.0312v3:PDF},
  keywords    = {cs.CV},
}

@Article{Mao2015,
  author      = {Junhua Mao and Jonathan Huang and Alexander Toshev and Oana Camburu and Alan Yuille and Kevin Murphy},
  title       = {Generation and Comprehension of Unambiguous Object Descriptions},
  abstract    = {We propose a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image, and which can also comprehend or interpret such an expression to infer which object is being described. We show that our method outperforms previous methods that generate descriptions of objects without taking into account other potentially ambiguous objects in the scene. Our model is inspired by recent successes of deep learning methods for image captioning, but while image captioning is difficult to evaluate, our task allows for easy objective evaluation. We also present a new large-scale dataset for referring expressions, based on MS-COCO. We have released the dataset and a toolbox for visualization and evaluation, see https://github.com/mjhucla/Google_Refexp_toolbox},
  date        = {2015-11-07},
  eprint      = {1511.02283v3},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1511.02283v3:PDF},
  keywords    = {cs.CV, cs.CL, cs.LG, cs.RO, I.2.6; I.2.7; I.2.10},
}

@InProceedings{Ghodsi2016,
  author    = {Ghodsi, Aneiss and DeNero, John},
  title     = {An Analysis of the Ability of Statistical Language Models to Capture the Structural Properties of Language},
  booktitle = {Proceedings of the 9th International Natural Language Generation conference},
  year      = {2016},
  pages     = {227--231},
  address   = {Edinburgh, UK},
  month     = sep #{ 5-8},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/W16-6637},
  url       = {https://www.aclweb.org/anthology/W16-6637},
}

@InProceedings{Frank2016,
  author = {Michael C. Frank},
  title  = {Rational speech act models of pragmatic reasoning in reference games},
  year   = {2016},
}

@Article{Franke2016,
  author    = {Michael Franke and Gerhard Jäger},
  title     = {Probabilistic pragmatics, or why Bayes’ rule is probably important for pragmatics},
  journal   = {Zeitschrift für Sprachwissenschaft},
  year      = {2016},
  volume    = {35},
  number    = {1},
  pages     = {3 - 44},
  address   = {Berlin, Boston},
  doi       = {https://doi.org/10.1515/zfs-2016-0002},
  publisher = {De Gruyter},
  url       = {https://www.degruyter.com/view/journals/zfsw/35/1/article-p3.xml},
}

@Article{Vijayakumar2016,
  author      = {Ashwin K Vijayakumar and Michael Cogswell and Ramprasath R. Selvaraju and Qing Sun and Stefan Lee and David Crandall and Dhruv Batra},
  title       = {Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models},
  abstract    = {Neural sequence models are widely used to model time-series data. Equally ubiquitous is the usage of beam search (BS) as an approximate inference algorithm to decode output sequences from these models. BS explores the search space in a greedy left-right fashion retaining only the top-B candidates - resulting in sequences that differ only slightly from each other. Producing lists of nearly identical sequences is not only computationally wasteful but also typically fails to capture the inherent ambiguity of complex AI tasks. To overcome this problem, we propose Diverse Beam Search (DBS), an alternative to BS that decodes a list of diverse outputs by optimizing for a diversity-augmented objective. We observe that our method finds better top-1 solutions by controlling for the exploration and exploitation of the search space - implying that DBS is a better search algorithm. Moreover, these gains are achieved with minimal computational or memory over- head as compared to beam search. To demonstrate the broad applicability of our method, we present results on image captioning, machine translation and visual question generation using both standard quantitative metrics and qualitative human studies. Further, we study the role of diversity for image-grounded language generation tasks as the complexity of the image changes. We observe that our method consistently outperforms BS and previously proposed techniques for diverse decoding from neural sequence models.},
  date        = {2016-10-07},
  eprint      = {1610.02424v2},
  eprintclass = {cs.AI},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1610.02424v2:PDF},
  keywords    = {cs.AI, cs.CL, cs.CV},
}

@Article{Chorowski2016,
  author      = {Jan Chorowski and Navdeep Jaitly},
  title       = {Towards better decoding and language model integration in sequence to sequence models},
  abstract    = {The recently proposed Sequence-to-Sequence (seq2seq) framework advocates replacing complex data processing pipelines, such as an entire automatic speech recognition system, with a single neural network trained in an end-to-end fashion. In this contribution, we analyse an attention-based seq2seq speech recognition system that directly transcribes recordings into characters. We observe two shortcomings: overconfidence in its predictions and a tendency to produce incomplete transcriptions when language models are used. We propose practical solutions to both problems achieving competitive speaker independent word error rates on the Wall Street Journal dataset: without separate language models we reach 10.6% WER, while together with a trigram language model, we reach 6.7% WER.},
  date        = {2016-12-08},
  eprint      = {1612.02695v1},
  eprintclass = {cs.NE},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1612.02695v1:PDF},
  keywords    = {cs.NE, cs.CL, cs.LG, stat.ML},
}

@InProceedings{Miltenburg2016,
  author    = {van Miltenburg, Emiel and Morante, Roser and Elliott, Desmond},
  title     = {Pragmatic Factors in Image Description: The Case of Negations},
  booktitle = {Proceedings of the 5th Workshop on Vision and Language},
  year      = {2016},
  pages     = {54--59},
  address   = {Berlin, Germany},
  month     = aug,
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/W16-3207},
  groups    = {Pragmatics},
  url       = {https://www.aclweb.org/anthology/W16-3207},
}

@Article{Vedantam2017,
  author      = {Ramakrishna Vedantam and Samy Bengio and Kevin Murphy and Devi Parikh and Gal Chechik},
  title       = {Context-aware Captions from Context-agnostic Supervision},
  abstract    = {We introduce an inference technique to produce discriminative context-aware image captions (captions that describe differences between images or visual concepts) using only generic context-agnostic training data (captions that describe a concept or an image in isolation). For example, given images and captions of "siamese cat" and "tiger cat", we generate language that describes the "siamese cat" in a way that distinguishes it from "tiger cat". Our key novelty is that we show how to do joint inference over a language model that is context-agnostic and a listener which distinguishes closely-related concepts. We first apply our technique to a justification task, namely to describe why an image contains a particular fine-grained category as opposed to another closely-related category of the CUB-200-2011 dataset. We then study discriminative image captioning to generate language that uniquely refers to one of two semantically-similar images in the COCO dataset. Evaluations with discriminative ground truth for justification and human studies for discriminative image captioning reveal that our approach outperforms baseline generative and speaker-listener approaches for discrimination.},
  date        = {2017-01-11},
  eprint      = {1701.02870v3},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1701.02870v3:PDF},
  keywords    = {cs.CV, cs.AI},
}

@InProceedings{Cao2017,
  author    = {Cao, Kris and Clark, Stephen},
  title     = {Latent Variable Dialogue Models and their Diversity},
  booktitle = {Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},
  year      = {2017},
  pages     = {182--187},
  address   = {Valencia, Spain},
  month     = apr,
  publisher = {Association for Computational Linguistics},
  abstract  = {We present a dialogue generation model that directly captures the variability in possible responses to a given input, which reduces the {`}boring output{'} issue of deterministic dialogue models. Experiments show that our model generates more diverse outputs than baseline models, and also generates more consistently acceptable output than sampling from a deterministic encoder-decoder model.},
  url       = {https://www.aclweb.org/anthology/E17-2029},
}

@Article{Freitag2017,
  author       = {Markus Freitag and Yaser Al-Onaizan},
  title        = {Beam Search Strategies for Neural Machine Translation},
  abstract     = {The basic concept in Neural Machine Translation (NMT) is to train a large Neural Network that maximizes the translation performance on a given parallel corpus. NMT is then using a simple left-to-right beam-search decoder to generate new translations that approximately maximize the trained conditional probability. The current beam search strategy generates the target sentence word by word from left-to- right while keeping a fixed amount of active candidates at each time step. First, this simple search is less adaptive as it also expands candidates whose scores are much worse than the current best. Secondly, it does not expand hypotheses if they are not within the best scoring candidates, even if their scores are close to the best one. The latter one can be avoided by increasing the beam size until no performance improvement can be observed. While you can reach better performance, this has the draw- back of a slower decoding speed. In this paper, we concentrate on speeding up the decoder by applying a more flexible beam search strategy whose candidate size may vary at each time step depending on the candidate scores. We speed up the original decoder by up to 43% for the two language pairs German-English and Chinese-English without losing any translation quality.},
  date         = {2017-02-06},
  doi          = {10.18653/v1/W17-3207},
  eprint       = {1702.01806v2},
  eprintclass  = {cs.CL},
  eprinttype   = {arXiv},
  file         = {online:http\://arxiv.org/pdf/1702.01806v2:PDF},
  journaltitle = {Proceedings of the First Workshop on Neural Machine Translation, 2017},
  keywords     = {cs.CL},
}

@InProceedings{Zarries2018,
  author    = {Zarrie{\ss}, Sina and Schlangen, David},
  title     = {Decoding Strategies for Neural Referring Expression Generation},
  booktitle = {Proceedings of the 11th International Conference on Natural Language Generation},
  year      = {2018},
  pages     = {503--512},
  address   = {Tilburg University, The Netherlands},
  month     = nov,
  publisher = {Association for Computational Linguistics},
  abstract  = {RNN-based sequence generation is now widely used in NLP and NLG (natural language generation). Most work focusses on how to train RNNs, even though also decoding is not necessarily straightforward: previous work on neural MT found seq2seq models to radically prefer short candidates, and has proposed a number of beam search heuristics to deal with this. In this work, we assess decoding strategies for referring expression generation with neural models. Here, expression length is crucial: output should neither contain too much or too little information, in order to be pragmatically adequate. We find that most beam search heuristics developed for MT do not generalize well to referring expression generation (REG), and do not generally outperform greedy decoding. We observe that beam search heuristics for termination seem to override the model{'}s knowledge of what a good stopping point is. Therefore, we also explore a recent approach called trainable decoding, which uses a small network to modify the RNN{'}s hidden state for better decoding results. We find this approach to consistently outperform greedy decoding for REG.},
  doi       = {10.18653/v1/W18-6563},
  url       = {https://www.aclweb.org/anthology/W18-6563},
}

@Article{Cohn-Gordon2018,
  author      = {Reuben Cohn-Gordon and Noah Goodman and Christopher Potts},
  title       = {Pragmatically Informative Image Captioning with Character-Level Inference},
  abstract    = {We combine a neural image captioner with a Rational Speech Acts (RSA) model to make a system that is pragmatically informative: its objective is to produce captions that are not merely true but also distinguish their inputs from similar images. Previous attempts to combine RSA with neural image captioning require an inference which normalizes over the entire set of possible utterances. This poses a serious problem of efficiency, previously solved by sampling a small subset of possible utterances. We instead solve this problem by implementing a version of RSA which operates at the level of characters ("a","b","c"...) during the unrolling of the caption. We find that the utterance-level effect of referential captions can be obtained with only character-level decisions. Finally, we introduce an automatic method for testing the performance of pragmatic speaker models, and show that our model outperforms a non-pragmatic baseline as well as a word-level RSA captioner.},
  date        = {2018-04-15},
  eprint      = {1804.05417v2},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1804.05417v2:PDF},
  keywords    = {cs.CL},
}

@InProceedings{Miltenburg2018,
  author    = {van Miltenburg, Emiel and Elliott, Desmond and Vossen, Piek},
  title     = {Measuring the Diversity of Automatic Image Descriptions},
  booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
  year      = {2018},
  pages     = {1730--1741},
  address   = {Santa Fe, New Mexico, USA},
  month     = aug,
  publisher = {Association for Computational Linguistics},
  abstract  = {Automatic image description systems typically produce generic sentences that only make use of a small subset of the vocabulary available to them. In this paper, we consider the production of generic descriptions as a lack of diversity in the output, which we quantify using established metrics and two new metrics that frame image description as a word recall task. This framing allows us to evaluate system performance on the head of the vocabulary, as well as on the long tail, where system performance degrades. We use these metrics to examine the diversity of the sentences generated by nine state-of-the-art systems on the MS COCO data set. We find that the systems trained with maximum likelihood objectives produce less diverse output than those trained with additional adversarial objectives. However, the adversarially-trained models only produce more types from the head of the vocabulary and not the tail. Besides vocabulary-based methods, we also look at the compositional capacity of the systems, specifically their ability to create compound nouns and prepositional phrases of different lengths. We conclude that there is still much room for improvement, and offer a toolkit to measure progress towards the goal of generating more diverse image descriptions.},
  url       = {https://www.aclweb.org/anthology/C18-1147},
}

@Article{Liu2018,
  author      = {Nelson F. Liu and Omer Levy and Roy Schwartz and Chenhao Tan and Noah A. Smith},
  title       = {LSTMs Exploit Linguistic Attributes of Data},
  abstract    = {While recurrent neural networks have found success in a variety of natural language processing applications, they are general models of sequential data. We investigate how the properties of natural language data affect an LSTM's ability to learn a nonlinguistic task: recalling elements from its input. We find that models trained on natural language data are able to recall tokens from much longer sequences than models trained on non-language sequential data. Furthermore, we show that the LSTM learns to solve the memorization task by explicitly using a subset of its neurons to count timesteps in the input. We hypothesize that the patterns and structure in natural language data enable LSTMs to learn by providing approximate ways of reducing loss, but understanding the effect of different training data on the learnability of LSTMs remains an open question.},
  date        = {2018-05-29},
  eprint      = {1805.11653v2},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1805.11653v2:PDF},
  keywords    = {cs.CL},
}

@Article{Lippi2018,
  author       = {Marco Lippi and Marcelo A Montemurro and Mirko Degli Esposti and Giampaolo Cristadoro},
  title        = {Natural Language Statistical Features of LSTM-generated Texts},
  abstract     = {Long Short-Term Memory (LSTM) networks have recently shown remarkable performance in several tasks dealing with natural language generation, such as image captioning or poetry composition. Yet, only few works have analyzed text generated by LSTMs in order to quantitatively evaluate to which extent such artificial texts resemble those generated by humans. We compared the statistical structure of LSTM-generated language to that of written natural language, and to those produced by Markov models of various orders. In particular, we characterized the statistical structure of language by assessing word-frequency statistics, long-range correlations, and entropy measures. Our main finding is that while both LSTM and Markov-generated texts can exhibit features similar to real ones in their word-frequency statistics and entropy measures, LSTM-texts are shown to reproduce long-range correlations at scales comparable to those found in natural language. Moreover, for LSTM networks a temperature-like parameter controlling the generation process shows an optimal value---for which the produced texts are closest to real language---consistent across all the different statistical features investigated.},
  date         = {2018-04-10},
  doi          = {10.1109/TNNLS.2019.2890970},
  eprint       = {1804.04087v2},
  eprintclass  = {cs.CL},
  eprinttype   = {arXiv},
  file         = {online:http\://arxiv.org/pdf/1804.04087v2:PDF},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems, 2019},
  keywords     = {cs.CL, cs.LG},
}

@InProceedings{Melas-Kyriazi2018,
  author    = {Melas-Kyriazi, Luke and Rush, Alexander and Han, George},
  title     = {Training for Diversity in Image Paragraph Captioning},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  year      = {2018},
  pages     = {757--761},
  address   = {Brussels, Belgium},
  month     = oct #{-} # nov,
  publisher = {Association for Computational Linguistics},
  abstract  = {Image paragraph captioning models aim to produce detailed descriptions of a source image. These models use similar techniques as standard image captioning models, but they have encountered issues in text generation, notably a lack of diversity between sentences, that have limited their effectiveness. In this work, we consider applying sequence-level training for this task. We find that standard self-critical training produces poor results, but when combined with an integrated penalty on trigram repetition produces much more diverse paragraphs. This simple training approach improves on the best result on the Visual Genome paragraph captioning dataset from 16.9 to 30.6 CIDEr, with gains on METEOR and BLEU as well, without requiring any architectural changes.},
  doi       = {10.18653/v1/D18-1084},
  url       = {https://www.aclweb.org/anthology/D18-1084},
}

@Article{Yuan2018,
  author  = {Arianna Yuan and Will Monroe and Yu Bai and Nate Kushman},
  title   = {Understanding the Rational Speech Act model},
  journal = {Cognitive Science},
  year    = {2018},
}

@Article{Cohn-Gordon2018a,
  author  = {Reuben Cohn-Gordon and Noah D. Goodman and Christopher Potts},
  title   = {An Incremental Iterated Response Model of Pragmatics},
  journal = {ArXiv},
  year    = {2018},
  volume  = {abs/1810.00367},
}

@Article{Shen2019,
  author      = {Sheng Shen and Daniel Fried and Jacob Andreas and Dan Klein},
  title       = {Pragmatically Informative Text Generation},
  abstract    = {We improve the informativeness of models for conditional text generation using techniques from computational pragmatics. These techniques formulate language production as a game between speakers and listeners, in which a speaker should generate output text that a listener can use to correctly identify the original input that the text describes. While such approaches are widely used in cognitive science and grounded language learning, they have received less attention for more standard language generation tasks. We consider two pragmatic modeling methods for text generation: one where pragmatics is imposed by information preservation, and another where pragmatics is imposed by explicit modeling of distractors. We find that these methods improve the performance of strong existing systems for abstractive summarization and generation from structured meaning representations.},
  date        = {2019-04-02},
  eprint      = {1904.01301v2},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1904.01301v2:PDF},
  keywords    = {cs.CL},
}

@InProceedings{Ippolito2019,
  author    = {Ippolito, Daphne and Kriz, Reno and Sedoc, Jo{\~a}o and Kustikova, Maria and Callison-Burch, Chris},
  title     = {Comparison of Diverse Decoding Methods from Conditional Language Models},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  year      = {2019},
  pages     = {3752--3762},
  address   = {Florence, Italy},
  month     = jul,
  publisher = {Association for Computational Linguistics},
  abstract  = {While conditional language models have greatly improved in their ability to output high quality natural language, many NLP applications benefit from being able to generate a diverse set of candidate sequences. Diverse decoding strategies aim to, within a given-sized candidate list, cover as much of the space of high-quality outputs as possible, leading to improvements for tasks that rerank and combine candidate outputs. Standard decoding methods, such as beam search, optimize for generating high likelihood sequences rather than diverse ones, though recent work has focused on increasing diversity in these methods. In this work, we perform an extensive survey of decoding-time strategies for generating diverse outputs from a conditional language model. In addition, we present a novel method where we over-sample candidates, then use clustering to remove similar sequences, thus achieving high diversity without sacrificing quality.},
  doi       = {10.18653/v1/P19-1365},
  url       = {https://www.aclweb.org/anthology/P19-1365},
}

@Article{Wang2019,
  author      = {Qingzhong Wang and Antoni B. Chan},
  title       = {Describing like humans: on diversity in image captioning},
  abstract    = {Recently, the state-of-the-art models for image captioning have overtaken human performance based on the most popular metrics, such as BLEU, METEOR, ROUGE, and CIDEr. Does this mean we have solved the task of image captioning? The above metrics only measure the similarity of the generated caption to the human annotations, which reflects its accuracy. However, an image contains many concepts and multiple levels of detail, and thus there is a variety of captions that express different concepts and details that might be interesting for different humans. Therefore only evaluating accuracy is not sufficient for measuring the performance of captioning models --- the diversity of the generated captions should also be considered. In this paper, we proposed a new metric for measuring the diversity of image captions, which is derived from latent semantic analysis and kernelized to use CIDEr similarity. We conduct extensive experiments to re-evaluate recent captioning models in the context of both diversity and accuracy. We find that there is still a large gap between the model and human performance in terms of both accuracy and diversity and the models that have optimized accuracy (CIDEr) have low diversity. We also show that balancing the cross-entropy loss and CIDEr reward in reinforcement learning during training can effectively control the tradeoff between diversity and accuracy of the generated captions.},
  date        = {2019-03-28},
  eprint      = {1903.12020v3},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1903.12020v3:PDF},
  keywords    = {cs.CV},
}

@Article{Holtzman2019,
  author      = {Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
  title       = {The Curious Case of Neural Text Degeneration},
  abstract    = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive. In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
  date        = {2019-04-22},
  eprint      = {1904.09751v2},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1904.09751v2:PDF},
  keywords    = {cs.CL},
}

@Article{Krahmer2011,
  author  = {Krahmer, Emiel and van Deemter, Kees},
  title   = {Computational Generation of Referring Expressions: A Survey},
  journal = {Computational Linguistics},
  year    = {2011},
  volume  = {38},
  month   = {01},
  doi     = {10.1162/COLI_a_00088},
  groups  = {Referring Expression Generation, Computational Linguistics, REG},
}

@InProceedings{Lu2017Adaptive,
author = {Lu, Jiasen and Xiong, Caiming and Parikh, Devi and Socher, Richard},
title = {Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning},
journal = {CVPR},
year = {2017}
}

@article{ackley1985learning,
  title={A learning algorithm for Boltzmann machines},
  author={Ackley, David H and Hinton, Geoffrey E and Sejnowski, Terrence J},
  journal={Cognitive science},
  volume={9},
  number={1},
  pages={147--169},
  year={1985},
  publisher={Elsevier}
}

@inproceedings{Johansson2008,
  title={Lexical diversity and lexical density in speech and writing},
  author={Victoria Johansson},
  year={2008}
}

@article{Jarvis2013,
author = {Jarvis, Scott},
year = {2013},
month = {03},
pages = {},
title = {Capturing the Diversity in Lexical Diversity},
volume = {63},
journal = {Language Learning},
doi = {10.1111/j.1467-9922.2012.00739.x}
}

@article{Zipf1937,
    author = {Zipf, George Kingsley},
    title = {Observations of the Possible Effect of Mental Age Upon the Frequency-Distribution of Words, from the Viewpoint of Dynamic Philology},
    journal = {The Journal of Psychology},
    volume = {4},
    number = {1},
    pages = {239-244},
    year  = {1937},
    publisher = {Routledge},
    doi = {10.1080/00223980.1937.9917534},
    URL = { 
            https://doi.org/10.1080/00223980.1937.9917534
    },
    eprint = { 
            https://doi.org/10.1080/00223980.1937.9917534
    }
}

@book{Zipf1935,
  address = {New York, NY, USA},
  author = {Zipf, George Kingsley},
  publisher = {Houghton-Mifflin},
  title = {The Psychobiology of Language},
  year = 1935
}

@article{Carroll1938,
  title={Diversity of vocabulary and the harmonic series law of word-frequency distribution},
  author={John B. Carroll},
  journal={The Psychological Record},
  year={1938},
  volume={2},
  pages={379-386}
}

@article{Brennan1996,
  title={Conceptual pacts and lexical choice in conversation.},
  author={Susan E. Brennan and Herbert H. Clark},
  journal={Journal of experimental psychology. Learning, memory, and cognition},
  year={1996},
  volume={22 6},
  pages={
          1482-93
        }
}

@Article{Brown1958,
  author  = {Roger Brown},
  title   = {How shall a thing be called?},
  journal = {Psychological Review},
  year    = {1958},
  volume  = {65},
  number  = {1},
  pages   = {14-21},
  url     = {https://pdfs.semanticscholar.org/673f/35c2530c0be65be72f9fa12d5e26f1e5adcc.pdf},
  file    = {Brown1958.odt:Brown1958.odt:OpenDocument text},
  groups  = {Object Naming / CogLi, General and Cognitive Lingustics, Theoretical Foundations},
}

@article{Rosch1976,
title = "Basic objects in natural categories",
journal = "Cognitive Psychology",
volume = "8",
number = "3",
pages = "382 - 439",
year = "1976",
issn = "0010-0285",
doi = "https://doi.org/10.1016/0010-0285(76)90013-X",
url = "http://www.sciencedirect.com/science/article/pii/001002857690013X",
author = "Eleanor Rosch and Carolyn B Mervis and Wayne D Gray and David M Johnson and Penny Boyes-Braem",
abstract = "Categorizations which humans make of the concrete world are not arbitrary but highly determined. In taxonomies of concrete objects, there is one level of abstraction at which the most basic category cuts are made. Basic categories are those which carry the most information, possess the highest category cue validity, and are, thus, the most differentiated from one another. The four experiments of Part I define basic objects by demonstrating that in taxonomies of common concrete nouns in English based on class inclusion, basic objects are the most inclusive categories whose members: (a) possess significant numbers of attributes in common, (b) have motor programs which are similar to one another, (c) have similar shapes, and (d) can be identified from averaged shapes of members of the class. The eight experiments of Part II explore implications of the structure of categories. Basic objects are shown to be the most inclusive categories for which a concrete image of the category as a whole can be formed, to be the first categorizations made during perception of the environment, to be the earliest categories sorted and earliest named by children, and to be the categories most codable, most coded, and most necessary in language."
}


@Article{Jolicoeur1984,
  author        = {Pierre Jolicoeur and Mark A. Gluck and Stephen M. Kosslyn},
  title         = {Pictures and names: Making the connection},
  journal       = {Cognitive Psychology},
  year          = {1984},
  volume        = {16},
  number        = {2},
  pages         = {243 - 275},
  issn          = {0010-0285},
  doi           = {https://doi.org/10.1016/0010-0285(84)90009-4},
  url           = {http://www.sciencedirect.com/science/article/pii/0010028584900094},
  __markedentry = {[simeon:1]},
  abstract      = {In order to identify an object sensory input must somehow access stored information. A series of results supports two general assertions about this process: First, objects are identified first at a particular level of abstraction which is neither the most general nor the most specific possible. Time to provide names more general than “entry point” names is predicted by the degree of association between the “entry point” concept and the required name, not by perceptual factors. In contrast, providing more specific names than that corresponding to the “entry point” concept does require more detailed perceptual analysis. Second, the particular entry point for a given object covaries with its typicality, which affects whether or not the object will be identified at the “basic” level. Atypical objects have their entry point at a level subordinate to the basic level. The generality and usefulness of the notion of “basic level” is discussed in the face of these results.},
  groups        = {Object Naming / CogLi, General and Cognitive Lingustics},
}
